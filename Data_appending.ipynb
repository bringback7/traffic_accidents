{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704120ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "data_zip = './dataset/data.zip'\n",
    "#file_name = 'data.zip'\n",
    "\n",
    "folder_path = \"./dataset/\"\n",
    "file_to_keep = \"data.zip\"\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if it's a file and not the specific file to keep\n",
    "    if os.path.isfile(file_path) and filename != file_to_keep:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed file: {filename}\")\n",
    "    elif os.path.isdir(file_path) and filename != file_to_keep:\n",
    "        shutil.rmtree(file_path)\n",
    "        print(f\"Removed directory: {filename} and its contents\")\n",
    "\n",
    "with zipfile.ZipFile(data_zip, \"r\") as zip_ref:\n",
    "    # Extract the raw file\n",
    "    zip_ref.extractall(\"dataset\")\n",
    "\n",
    "print(\"Extraction completed.\")\n",
    "if os.path.exists('./dataset/__MACOSX'):\n",
    "    shutil.rmtree('./dataset/__MACOSX')\n",
    "    print('Directory __MACOSX removed')\n",
    "    \n",
    "# Root directory where the directories are located\n",
    "os.rename('./dataset/data_GIS_2020', './dataset/data_2020')\n",
    "os.rename('./dataset/data_GIS_2022', './dataset/data_2022')\n",
    "os.rename('./dataset/data_web_2021', './dataset/data_2021')\n",
    "os.rename('./dataset/dataGIS_rok_2017', './dataset/data_2017')\n",
    "os.rename('./dataset/dataGIS_rok_2018', './dataset/data_2018')\n",
    "os.rename('./dataset/dataGIS_rok_2019', './dataset/data_2019')\n",
    "os.rename('./dataset/dataGIS2016', './dataset/data_2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef818633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nepříchází v úvahu                          557841\n",
       "jiná překážka                                43641\n",
       "odrazník, patník                             27507\n",
       "sloup                                        19879\n",
       "svodidlo                                     19190\n",
       "strom                                        17632\n",
       "zeď, pevná část mostů                        16974\n",
       "překážka vzniklá stavební činností            2416\n",
       "překážka vzniklá provozem jiného vozidla      1109\n",
       "závory železničního přejezdu                   838\n",
       "Name: Srazka_s_pevnou_prekazkou, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    557841\n",
       "1    149186\n",
       "Name: Srazka_s_pevnou_prekazkou, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regions_mapping = {\n",
    "    '00.csv' : 'Praha',\n",
    "    '01.csv' : 'Stredocesky',\n",
    "    '02.csv' : 'Jihocesky',\n",
    "    '03.csv' : 'Plzensky',\n",
    "    '04.csv' : 'Ustecky',\n",
    "    '05.csv' : 'Kralovehradecky',\n",
    "    '06.csv' : 'Jihomoravsky',\n",
    "    '07.csv' : 'Moravskoslezsky',\n",
    "    '14.csv' : 'Olomoucky',\n",
    "    '15.csv' : 'Zlinsky',\n",
    "    '16.csv' : 'Vysocina',\n",
    "    '17.csv' : 'Pardobicky',\n",
    "    '18.csv' : 'Liberecky',\n",
    "    '19.csv' : 'Karlovarsky',\n",
    "} \n",
    "\n",
    "\n",
    "header_data = pd.read_csv(\"header.csv\",sep=\";\")\n",
    "columns = list(header_data.columns.values)\n",
    "#display(columns)\n",
    "data = pd.DataFrame()\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename != \"data.zip\":\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(f\"Folder:{filename}\")\n",
    "        for file in os.listdir(file_path):\n",
    "            if file != \"CHODCI.csv\" and os.stat(os.path.join(file_path,file)).st_size > 0:\n",
    "                print(f\"CSV file: {file}\")\n",
    "                path = os.path.join(file_path,file)\n",
    "                csv_data = pd.read_csv(path, sep=';', header=None, names=columns, encoding=\"cp1250\")\n",
    "                if file in regions_mapping.keys():\n",
    "                    csv_data['region'] = regions_mapping[file]\n",
    "                #csv_data = pd.concat([header_data, csv_data], axis=0, ignore_index=True)\n",
    "                data = data.append(csv_data)\n",
    "\n",
    "\n",
    "#df = pd.read_csv('./dataset/data_GIS_2020/01.csv',sep=';', header=None,encoding=\"cp1250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"all_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
